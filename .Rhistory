company[[i-1]] <- i
}
plot(company,rho,main = 'spearman')
#axis(1, c('Paramount','Sony','Universal','Disny','Warner Bro'),las=2)
#plot the rho with pearson
rho <- list()
company <- list()
for (i in 2:6){
corr <- cor.test(x=movies_cor[,i], y=movies_cor$profit,method = 'pearson')
rho[[i-1]] <- corr$estimate
company[[i-1]] <- i
}
plot(company,rho,main = 'pearson')
G = factor(movie_OH$genres)
dumm = as.data.frame(model.matrix(~G)[,-1])
movie_OH = cbind(movie_OH, dumm)
#str(movie_OH)
#get a subset for linear model and scale the variables
movie_r <- subset(movies,select = c(profit,budget,popularity,runtime,vote,genres,month,score,company))
movie_r$budget <- scale(movie_r$budget)
movie_r$profit <- scale(movie_r$profit)
movie_r$popularity <- scale(movie_r$popularity)
movie_r$runtime <- scale(movie_r$runtime)
movie_r$vote <- scale(movie_r$vote)
movie_r$month <- as.factor(movie_r$month)
#build the model and print out the summary
p.linear <- lm(profit~.,data=movie_r)
print(summary(p.linear))
#load the package first
loadPkg("leaps")
loadPkg("ISLR")
#using backward elimination to select features and draw plots
movie_r$month <- as.factor(movie_r$month)
reg.best <- regsubsets(profit~. , data = movie_r, nvmax = 14, nbest = 1, method = "backward")
plot(reg.best, scale = "adjr2", main = "Adjusted R^2")
#plot(reg.best, scale = "r2", main = "R^2")
plot(reg.best, scale = "bic", main = "BIC")
plot(reg.best, scale = "Cp", main = "Cp")
#summary(reg.best)
loadPkg("car")
summaryRegForward = summary(reg.best)
# Adjusted R2
subsets(reg.best, statistic="adjr2", legend = FALSE, main = "Adjusted R^2")
# Mallow Cp
res.legend <- subsets(reg.best, statistic="cp", legend = FALSE , main = "Mallow Cp")
# this output gives the list of variables and their abbreviations
#str(movie_OH)
#using the dataframe with each categorical in separate columns and scale it
movie_OH$budget <- scale(movie_OH$budget)
movie_OH$profit <- scale(movie_OH$profit)
movie_OH$popularity <- scale(movie_OH$popularity)
movie_OH$runtime <- scale(movie_OH$runtime)
movie_OH$vote <- scale(movie_OH$vote)
#build the new model with less features
p.linear2 <- lm(profit~budget+vote+M5+M6+M12+GAnimation+GFamily,data=movie_OH)
#print the result of the linear model
summary(p.linear2)
#get a new movie dataset for ridge regression and scale it
m_r <- subset(movies,select = c(company,month,genres,popularity,vote,score,budget,profit))
m_r$month <- as.factor(m_r$month)
m_r$budget <- scale(m_r$budget)
m_r$score <- scale(m_r$score)
m_r$popularity<-scale(m_r$popularity)
m_r$profit<-scale(m_r$profit)
m_r$vote<-scale(m_r$vote)
#split the independent and dependent variables
xr=model.matrix(profit~.,m_r)[,-1]
yr=m_r$profit
loadPkg("glmnet")
#set the lambdas grid
lambdas=10^seq(10,-10,by = -.1) # prepare log scale grid for λ values, from 10^10 to 10^-10
ridge.mod=glmnet(xr,yr,alpha=0,lambda=lambdas) # build the ridge model.
#get the dimension of the model
#dim(coef(ridge.mod))
#plot the coefficient
plot(ridge.mod)
#get the fit model
fit <- ridge.mod$lambda
#summary(fit)
#get the best lambda using cross validation
cv_fit <- cv.glmnet(xr, yr, alpha = 0, lambda = lambdas)
plot(cv_fit)
bestlam = cv_fit$lambda.min  # Select lamda that minimizes training MSE
bestlam
fit<-cv_fit$glmnet.fit
y_predicted <- predict(fit, s = bestlam, newx = xr)
# Sum of Squares Total and Error
sst <- sum((yr - mean(yr))^2)
sse <- sum((y_predicted - yr)^2)
# R squared
rsq <- 1 - sse / sst
rsq
#mean((lasso.pred-y_test)^2)
out = cv.glmnet(xr, yr, alpha = 1,lambda = lambdas)# Fit lasso model on full dataset
bl <- out$lambda.min
#lasso.pred=predict(out,s=bl,newx=xr)
yp <- predict(out, s = bl, newx = xr)
# Sum of Squares Total and Error
Lsst <- sum((yr - mean(yr))^2)
Lsse <- sum((yp - yr)^2)
# R squared
Lrsq <- 1 - Lsse / Lsst
Lrsq
lasso_coef = predict(out, type = "coefficients", s = bl)[1:38,] # Display coefficients using λ chosen by CV
#lasso_coef
lasso_coef[lasso_coef!=0]
lasso_coef[lasso_coef==0]
#str(movies_rf)
# install.packages('caTools')
library(caTools)
movies$month <- as.integer(movies$month)
movie_RF <- subset(movies,select = c(company,genres,month,runtime,budget,popularity,score,vote))
set.seed(123)
split = sample.split(movie_RF, SplitRatio = 0.8)
training_set = subset(movie_RF, split == TRUE)
test_set = subset(movie_RF, split == FALSE)
RFR = randomForest(x = movie_RF,
y = movie$profit,
ntree = 500)
print(RFR)
plot(RFR)
#Set the populartiy as same as the movie forzen's
Frozen2a <- data.frame(company = 'Walt Disney',genres = 'Animation',month = 11, runtime = 104 ,budget = 33000000, popularity = 165.13, score = 6.79,vote = 5295)
#fit the levels of company and genre
levels(Frozen2a$company) <- RFR$forest$xlevels$company
levels(Frozen2a$genres) <- RFR$forest$xlevels$genres
Frozen2_profita = predict(RFR, Frozen2a)
#build an ultimate linear model with some polynomials
f.model <- lm(profit ~ poly(popularity,10)+poly(vote,10)+company+month+genres+poly(runtime,2)+poly(budget,3)+poly(score,6), data = movies)
summary(f.model)
Ff <- data.frame(company = 'Walt Disney',genres = 'Animation',month = 11, runtime = 104 ,budget = 150000000, popularity = 165.13, score = 7.3,vote = 5295)
Poly_predict <- predict(f.model,Ff)
PCAxform <- function(df, z=TRUE) {
#' Obtain the dataframe with the Principal Components after the rotation.
#' ELo 201903 GWU DATS
#' @param df The dataframe.
#' @param z T/F or 0/1 for z-score to be used
#' @return The transformed dataframe.
#' @examples
#' tmp = PCAxform(USArrests,TRUE)
z = ifelse(z==TRUE || z=="true" || z=="True" || z=="T" || z=="t" || z==1 || z=="1", TRUE, FALSE) # standardize z
if(z) { df = data.frame(scale(df))}  # scale not safe for non-numeric colunms, but PCA requires all variables numerics to begin with.
nmax = length(df)
pr.out = prcomp(df,scale=z)
df1 = data.frame()
cnames = c()
for( i in 1:nmax ) {
vec = 0
cnames = c( cnames, paste("PC",i, sep="") )
for( j in 1:nmax ) { vec = vec + pr.out$rotation[j,i]*df[,j] }
if( length(df1)>0 ) { df1 = data.frame(df1,vec) } else { df1 = data.frame(vec) }
}
colnames(df1) <- cnames
return(df1)
}
# To-be-implemented: for z=TRUE, it will be better to have the z-scaling option for x-vars and y separately. It is actually convenient keep y in original units.
PCRxform <- function(df, y, zX=TRUE, zy=FALSE) {
#' Obtain the dataframe with the Principal Components after the rotation for PCRegression. Requires related function PCAxform()
#' ELo 201903 GWU DATS
#' @param df The dataframe.
#' @param y The y-variable column index number(int), or the name of y-variable
#' @param zX T/F or 0/1 for z-score used on X-variables
#' @param zy T/F or 0/1 for z-score used on the target y-variable
#' @return The transformed dataframe.
#' @examples
# take care of y target
zy = ifelse(zy==TRUE || zy=="true" || zy=="True" || zy=="T" || zy=="t" || zy==1 || zy=="1", TRUE, FALSE) # standardize target y
if( is.integer(y) ) { # y is integer
if( y>length(df) || y<1 ) {
print("Invalid column number")
return(NULL)
}
if(zy) { df1 = data.frame( scale(df[y]) ) } else { df1 = df[y] } # save y-var in df1
df = df[-y] # remove y-variable in df
} else { # y is not integer, so interpret as name
if(zy) { df1 = data.frame( scale( df[names(df) == y] ) ) } else { df1 = df[names(df) == y] }
df = df[names(df) != y] # remove y-variable in df
}
if( length(df1)<1 ) {
print("Variable name not found in data.frame")
return(NULL)
}
# now transform X-vars
zX = ifelse(zX==TRUE || zX=="true" || zX=="True" || zX=="T" || zX=="t" || zX==1 || zX=="1", TRUE, FALSE) # standardize X-vars
df2 = PCAxform(df,zX)
df1 = data.frame(df1,df2) # piece them back together
return(df1)
}
loadPkg("pls")
loadPkg("mice")
#loadPkg("ISLR")
pr = prcomp(movie_num[c(1:6)] , scale =FALSE)
pr_scale = prcomp(movie_num[c(1:6)], scale =TRUE)
summary(pr)
#pr$rotation
summary(pr_scale)
#pr_scale$rotation
pr.var <- (pr$sdev^2)
pve <- pr.var/sum(pr.var)
plot(cumsum(pve), xlab="Principal Component (standardized)", ylab ="Cumulative Proportion of Variance Explained",ylim=c(0,1),type="b", main ="Non-centered version")
pr_scale.var <- (pr_scale$sdev^2)
pve_scale  <- pr_scale.var/sum(pr_scale.var)
plot(cumsum(pve_scale), xlab="Principal Component (non-standardized)", ylab ="Cumulative Proportion of Variance Explained",ylim=c(0,1),type="b", main ="Centered version")
# we used the train and test sets in linear regression model
# at first we use the PCRxform function (Prof. EL) to scale and rotate
# training set
# we do not scale the response revenue but scale all predictors
movie_pcr = PCRxform(train1[c(1:6)],"revenue",TRUE,FALSE)  # scaled predictors
#movie_pcr
# testing set
movie_pcr_test = PCRxform(test1[c(1:6)],"revenue",TRUE,FALSE)
#movie_pcr_test
# non-centered version, nothing is scaled
movie_pcr.nc = PCRxform(train1[c(1:6)],"revenue",FALSE, FALSE)  # non-scaled predictors
#movie_pcr.nc
movie_pcr.nc_test = PCRxform(test1[c(1:6)],"revenue",FALSE, FALSE)
#movie_pcr.nc_test
# scaled data
pcr.fit <- pcr(revenue~.,data=movie_pcr,scale=FALSE,validation="CV") # build the model, as we scaled data before we use scale = F here
# non-scaled data
pcr.fit.nc <- pcr(revenue~.,data=movie_pcr.nc,scale=FALSE,validation="CV")
validationplot(pcr.fit.nc,val.type="MSEP", legend="topright")
validationplot(pcr.fit.nc,val.type="R2")
validationplot(pcr.fit,val.type="MSEP", legend="topright") # validation with MSEP & R2
validationplot(pcr.fit,val.type="R2")
coefplot(pcr.fit, intercept=TRUE) # plot coefficients of different components
# position 1 is the intercept, the first PC starts at position 2
# we can see the summary of the model
summary(pcr.fit.nc)
summary(pcr.fit)
# We only use the centered version as it is better than non-centered version
variance.pcr = c(1:5) # create a vector to store the variances for different numbers of components
for (i in 1:5) {
pcr_pred <- predict(pcr.fit, movie_pcr_test , ncomp = i); # predicting the PCR model on the testing set
# calculate the variance by returning the mean of  [predicted value - mean(actual values)] ^2
variance.pcr[i] = mean((pcr_pred - mean(movie_pcr_test$revenue))^2)
# calculate the variance by taking mean of( (predicted value - mean(actual values) ^2 )
}
var.pcr.df = as.data.frame(cbind(variance=variance.pcr, components = c(1:5)))
#pred_act <- data.frame(cbind(pcr_pred, movie_pcr_test$revenue))
ggplot(data=var.pcr.df) +
geom_line(aes(x = components, y = variance)) +
geom_point(aes(x = components, y = variance)) +
theme_light()
pcr_lm5 <- lm(revenue ~ PC1 + PC2 , data = movie_pcr.nc) # linear model with PC1 and PC2
summary(pcr_lm5)
vif(pcr_lm5)
pcr_lm4 <- lm(revenue ~ PC1 + PC2 , data = movie_pcr)
summary(pcr_lm4)
vif(pcr_lm4)
AIC(object = pcr_lm4)
BIC(object = pcr_lm4)
AIC(object = pcr_lm5)
BIC(object = pcr_lm5)
#str(movie)
if (require("pls")) {detach("package:pls", unload = T)  # for some reason package "pls" made the corrplot not proper so I detach it after using
}
prd_pcr <- predict(pcr_lm4, newdata=movie_pcr_test)
regr.eval(movie_pcr_test$revenue, prd_pcr)
# Prior check the dependence of genres and profitable
contable1 <- table(movie$genres, movie$profitable)
chisqres1 = chisq.test(contable1)
chisqres1
# Prior check the dependence of company and profitable
contable2 <- table(movie$company, movie$profitable)
chisqres2 = chisq.test(contable2)
chisqres2
# Prior check the dependence of season and profitable
contable3 <- table(movie$season, movie$profitable)
chisqres3 = chisq.test(contable3)
chisqres3
# we do some preparation with the data for our logit model
movie_nd <- movie_num # duplicate the dataframe of numerical variables
# append back the other columns
movie_nd$genres = movie$genres
movie_nd$company = movie$company
movie_nd$season = movie$season
movie_nd$y = movie$profitable # profitable column (negative profit = 0, positive profit = 1) is saved as y
str(movie_nd)
# split the train and test sets with ratio 50:50
#set.seed(1)
#movie_sample1 <- sample(2, nrow(movie_scale), replace=TRUE, prob=c(0.50, 0.50))
# create train and test sets
#train2 <- movie_scale[movie_sample1==1, 1:9]
#test2 <- movie_scale[movie_sample1==2, 1:9]
# Budget and revenue are enough to decide the profitable as the profit is calculated as revenue subtracted by budget. Our pre-test with "bestglm" also shows the same result.
loadPkg("bestglm")
#res.bestglm0 <- bestglm(Xy = movie_nd, family = binomial,
# IC = "AIC",                 # Information criteria for
#method = "exhaustive")
#summary(res.bestglm)
#res.bestglm0$BestModels
# we will use the same train and test sets as in previous chapters
# remove revenue column and use other predictors in train and test sets
train3 <- movie_nd[movie_sample == 1, 2:10] # revenue column is 1, we do not include it
test3 <- movie_nd[movie_sample == 2, 2:10]
dim(train3)
dim(test3)
prf_glm <- glm(y ~ ., data = train3, family = "binomial")
summary(prf_glm)
# check exp.coef
exp(coef(prf_glm))[24:28] # company
exp(coef(prf_glm))[7:23] # genres
exp(coef(prf_glm))[29:31] # seasons
#length(coef(prf_glm))
loadPkg("aod")  # Analysis of Overdispersed Data, used wald.test in logit example
wald.test(b = coef(prf_glm), Sigma = vcov(prf_glm), Terms = 7:23)
wald.test(b = coef(prf_glm), Sigma = vcov(prf_glm), Terms = 24:28)
wald.test(b = coef(prf_glm), Sigma = vcov(prf_glm), Terms = 29:31)
#drop revenue
res.bestglm <- bestglm(Xy = train3, family = binomial,
IC = "AIC",                 # Information criteria for
method = "exhaustive")
#summary(res.bestglm)
kable(res.bestglm$BestModels)
#summary(res.bestglm$BestModels)
prf_glm0 <- glm(y ~  budget + score + vote + company + season, data = train3, family = "binomial")
summary(prf_glm0)
#AIC(prf_glm0) # we can check AIC and BIC
#BIC(prf_glm0)
kable(as.data.frame(cbind("exponentiated coefficient" = exp(coef(prf_glm0)))))
prof_glm_pred = predict(object = prf_glm0, test3, type = c("response")) # predict the model on testing data and return predicted probabilities
loadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
# best model
prf_Hos0 = hoslem.test(test3$y, prof_glm_pred) # Hosmer and Lemeshow test, a chi-squared test
prf_Hos0
loadPkg("pROC")
h0 <- roc(test3$y ~ prof_glm_pred) # using the model on testing data and see the ROC curve and AUC
#auc(h0) # area-under-curve prefer 0.8 or higher.
plot(h0)
loadPkg("pscl") # use pR2( ) function to calculate McFadden statistics for model eval
prf_mcFadden = pR2(prf_glm0)
prf_mcFadden
#confusion matrix
loadPkg("caret")
logit_accuracy <- c(1:5)
logit_kappa <- c(1:5)
threshold_logit <- c(0.5, 0.6, 0.7, 0.8, 0.9) # set threshold for predicted probabilities
j = 1
for (i in c(0.5, 0.6, 0.7, 0.8, 0.9)) {
conf_matrix <- confusionMatrix(data = as.factor(as.integer(prof_glm_pred>i)), reference = test3$y); # using the model on the testing data
logit_accuracy[j] <- conf_matrix$overall[1]*100;
logit_kappa[j] <- conf_matrix$overall[2]
j = j+1
}
# lower threshold does not guarantee better accuracy, it depends on different datasets
# we can see the accuracy when threshold = 0.54 is better than 0.5
# confusionMatrix(data = as.factor(as.integer(prof_glm_pred>0.54)), reference = test3$y)
prediction = as.factor(as.integer(prof_glm_pred>0.54))
actual = test3$y
CrossTable(actual, prediction, prop.chisq = FALSE)
# the accuracy at 0.5 is 0.819 while the accuracy at 0.54 is 0.82
# combine results into a dataframe
logit_prediction <- as.data.frame(cbind(threshold = threshold_logit, accuracy = logit_accuracy, kappa = logit_kappa))
kable(logit_prediction)
loadPkg("ISLR")
loadPkg("tree")
loadPkg("rpart")
loadPkg("rpart.plot")
loadPkg("rattle") # For fancyRpartPlot (Trees) Answer "no" on installing from binary source
# we use the same training and testing data so that we can compare Classification Tree to Logit Regression
prf_dt <- rpart(y~., method = "class", data=train3) #rpart to build our tree
#summary(prf_dt) # detailed summary of splits
#prf_dt$variable.importance#variable importance
#printcp(prf_dt) # display the results
# plot tree
#prp(prf_dt, main = "Classification Trees for Profit Status")
#rpart.plot(prf_dt,main = "Classification Trees for Profit Status")
fancyRpartPlot(prf_dt)
#printcp(prf_dt) # display the results
plotcp(prf_dt) # visualize cross-validation results
prf_dt_prune <- prune(prf_dt, cp = prf_dt$cptable[which.min(prf_dt$cptable[,"xerror"]),"CP"]) # prune trees at cp where xerror is minimum
#prf_dt_prune <- prune(prf_dt, cp = prf_dt$cptable[4,"CP"])
# plot tree
#prp(prf_dt_prune, main = "Classification Trees for Profit Status")
#rpart.plot(prf_dt_prune,main = "Classification Trees for Profit Status")
fancyRpartPlot(prf_dt_prune)
prf_dt.pred <- predict(prf_dt_prune, test3, type = "class" ) # predict the model on the testing data
#table_dt <- table(actual = test3$y, prediction = prf_dt.pred) # create a confusion matrix of predicted and actual values
#kable(table_dt)
prediction = prf_dt.pred
actual = test3$y
CrossTable(actual, prediction, prop.chisq = FALSE)
# Accuracy Calculation
#sum(diag(table_dt))/sum(table_dt) # sum(true positive + false negative)/ total
#confusionMatrix(reference = test3$y, data = prf_dt.pred)
#length(prf_dt.pred)
# I see the method to plot ROC for classification tree in youtube and stackoverflow
# There is an option: type = "prob" when predict rpart object, it return predicted probabilities by the classification tree
# I then realize that the values with predicted probabilites > 0.5 are the values predicted as 1 in the above method (chunk Q92)
# I create the another confusion matrix for this part and set threshold = 0.5 and see that the confusion matrices are also similar
# prediction using type = "prob"
prf_dt.pred1 <- predict(prf_dt_prune, test3, type = "prob" )
#prf_dt.conf <- confusionMatrix(data = as.factor(as.integer(prf_dt.pred1[,2]>0.5)), reference = test3$y)
# the accuracy will be the same as the accuracy we calculate when setting type=class, we can see the results to check it
#prf_dt.conf # the accuracy is also 80.5% and the confusion matrix is the same too
#plot ROC and see AUC
h_dt <- roc(test3$y ~ prf_dt.pred1[,2])
#auc(h_dt)
plot(h_dt)
chooseK = function(k, train_set, val_set, train_class, val_class){
# Build knn with k neighbors considered.
class_knn = knn(train = train_set,    #<- training set cases
test = val_set,       #<- test set cases
cl = train_class,     #<- category for classification
k = k,                #<- number of neighbors considered
use.all = TRUE)       #<- control ties between class assignments
#   If true, all distances equal to the kth
#   largest are included
tab = table(class_knn, val_class)
# Calculate the accuracy.
accu = sum(tab[row(tab) == col(tab)]) / sum(tab)
cbind(k = k, accuracy = accu)
}
loadPkg("class")
#test3
#train3
loadPkg("gmodels")
knn_profit <- knn(train = train3[c(1:5)], test = test3[c(1:5)], cl=train3$y, k=3)
prediction =  knn_profit
actual = test3$y
CrossTable(actual,prediction, prop.chisq = FALSE)
knn_k_profit = sapply(seq(1, 21, by = 2),  #<- set k to be odd number from 1 to 21
function(x) chooseK(x,
train_set = train3[c(1:5)],
val_set = test3[c(1:5)],
train_class = train3$y,
val_class = test3$y))
# Reformat the results to graph the results.
#str(knn_different_k)
knn_k_profit = data.frame(k = knn_k_profit[1,],
accuracy = knn_k_profit[2,])
# Plot accuracy vs. k.
ggplot(knn_k_profit,
aes(x = k, y = accuracy)) +
geom_line(color = "orange", size = 1.5) +
geom_point(size = 3) +
theme_bw()
#theme(plot.title = element_text(hjust=0.5, size = 15, face = "bold.italic"))
knn_profit <- knn(train = train3[c(1:5)], test = test3[c(1:5)], cl=train3$y, k=7)
loadPkg("pander")
prediction =  knn_profit
actual = test3$y
CrossTable(actual,prediction, prop.chisq = FALSE)
# we will subset our data to get the movies from 1995-2016 since we have consistent data in that range
# we use time series with frequency = 4 (by quarter) (there are months without movie records so we cannot do time series with freq = 12)
movie_ts <- subset(movie, (year > 1994)) # subset data after 1994
movie_ts <- subset(movie_ts, select = c("revenue", "year", "quarter")) # select 3 columns we use for time series
movie_ts <- movie_ts[order(movie_ts$year),] # order by year
#unique(movie_ts$year)
#str(movie_ts)
loadPkg("dplyr")
movie_ts = movie_ts %>% group_by(year, quarter) %>% summarise_each(funs(sum)) # calculate the total revenue for each quarter in each year
movie_ts$quarter <- factor(movie_ts$quarter, levels = c("Q1", "Q2", "Q3", "Q4")) # reorder the factor levels
movie_ts <- movie_ts[order(movie_ts$year, movie_ts$quarter),] # order by year then by quarter
#movie_ts
# divide the data into 2 sets: training and testing
movie.ts <- ts(movie_ts$revenue, frequency = 4, start = c(1995,1), end = c(2010,4)) # training data from 1995-2010
movie.ts.test <- ts(tail(movie_ts, 23)$revenue, frequency = 4, start = c(2011,1), end = c(2016,3)) # testing data from 2011-2016, used for evaluating our time series model
#movie.ts.test
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
ggtitle("Revenue distribution by quarter") +
geom_boxplot(fill = c("red","dodgerblue","yellow","green"),alpha = 0.8) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
plot(movie.ts, xlab = "Year", ylab="Revenue")
movie_dcp <- decompose(movie.ts)
summary(movie_dcp$seasonal)
summary(movie_dcp$random)
plot(movie_dcp)
movie.ts.smth <- HoltWinters(movie.ts)
movie.ts.smth
movie.ts.smth$SSE
plot(movie.ts.smth)
loadPkg("forecast")
#accuracy(movie_hw)
movie_ft <- forecast(movie.ts.smth, h=23)
plot(movie_ft)
#sm <- ma(movie.ts, order=4) # 4 quarters moving average
#lines(sm, col="red") # plot
plot(movie_ft)
lines(movie.ts.test, col = 'red')
#ggplot(movie_hw)
legend("topleft",lty=1,bty = "n",col=c("red","blue"),c("actual","predicted"))
loadPkg("highcharter")
hchart(movie_ft) %>%
hc_add_series_ts(movie.ts.test, color = "red", name = "ACTUAL") # plot the predicted and actual values in testing data, and the values in training data
# we can have a more detailed plot with only predicted and actual values in testing data
highchart(type="stock") %>%        # try type = "chart", "stock" for different visualizations
hc_chart(type = "line") %>%      # try type = "line", bar", "column" for different visualizations
hc_add_series_ts(movie.ts.test,name = "ACTUAL", color = "red" ) %>%   # plot the actual data labeled by red color
hc_add_series(name = "PREDICTED", movie_ft, color = "blue" )  %>%     # plot the hw predictions labeled by blue color
hc_legend(align = "left", verticalAlign = "top",
layout = "vertical", x = 0, y = 100)
movie_arima <- auto.arima(movie.ts) # create arima model
movie_arima <- forecast(movie_arima, h=23) # see how it forcast
plot(movie_arima)
#movie_arima
plot(movie_arima)
lines(movie.ts.test, col = 'red')
legend("topleft",lty=1,bty = "n",col=c("red","blue"),c("actual","predicted"))
hchart(movie_arima) %>%
hc_add_series_ts(movie.ts.test, color = "red", name = "ACTUAL")  # general graph
# more detailed graph, I try different stuffs here
highchart(type="chart") %>%        # try type = "chart", "stock" for different visualizations
hc_chart(type = "column") %>%      # try type = "line", bar", "column" for different visualizations
hc_add_series_ts(movie.ts.test,name = "ACTUAL", color = "red" ) %>%   # plot the actual data labeled by red color
hc_add_series(name = "PREDICTED", movie_arima, color = "blue" )  %>%     # plot the hw predictions labeled by blue color
hc_legend(align = "left", verticalAlign = "top",
layout = "vertical", x = 0, y = 100)
kable(accuracy(movie_ft, movie.ts.test))
kable(accuracy(movie_arima, movie.ts.test))
