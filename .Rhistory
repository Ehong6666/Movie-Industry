actual_pred_tree.train <- as.data.frame(cbind(actuals = train1_full$revenue, predicteds = rev_tree_pred.train))
metrics_train_tree <- regr.eval(actual_pred_tree.train$actuals, actual_pred_tree.train$predicteds)
metrics_train_tree[c(1,3)]
printcp(rev_tree)
plotcp(rev_tree) # visualize cross-validation results
# prune the tree for optimization and avoid overfitting
rev_tree$cptable[,"xerror"] # we can see the lowest xerror
# choose Cp with mininum xerror and prune the tree
rev_tree_prune <- prune(rev_tree, cp = rev_tree$cptable[8,"CP"])
# testing
rev_tree_pred.test <- predict(rev_tree_prune, newdata = test1_full)
actual_pred_tree.test <- as.data.frame(cbind(actuals = test1_full$revenue, predicteds = rev_tree_pred.test))
metrics_test_tree <- regr.eval(actual_pred_tree.test$actuals, actual_pred_tree.test$predicteds)
metrics_test_tree[c(1,3)]
# training
rev_tree_pred.train <- predict(rev_tree_prune)
actual_pred_tree.train <- as.data.frame(cbind(actuals = train1_full$revenue, predicteds = rev_tree_pred.train))
metrics_train_tree <- regr.eval(actual_pred_tree.train$actuals, actual_pred_tree.train$predicteds)
metrics_train_tree[c(1,3)]
# we can see the results are the same as in the original tree
set.seed(123) # set.seed to make sure the selection of tree samples are the same if we re-run the code
rev_rf = randomForest(revenue~. , train1_full, ntree = 350) # construct RF model on training data, we set the number of trees as 350
rev_rf # the results of the model
randomForest::importance(rev_rf) # the importance of each predictor
plot(rev_rf)
#rev_rf$mse
# predicting the model on the testing data
rev_rf.test <- predict(rev_rf, test1_full)
actual_pred_rf.test <- as.data.frame(cbind(actuals = test1_full$revenue, predicteds = rev_rf.test))
metrics_test_rf  <- regr.eval(actual_pred_rf.test$actuals, actual_pred_rf.test$predicteds)
metrics_test_rf[c(1,3)]
#rev_rf$predicted
rev_rf.train <- predict(rev_rf) # same results as rev_rf$predicted, both codes return the predicted values in the training set
actual_pred_rf.train <- as.data.frame(cbind(actuals = train1_full$revenue, predicteds = rev_rf.train))
metrics_train_rf <- regr.eval(actual_pred_rf.train$actuals, actual_pred_rf.train$predicteds)
metrics_train_rf[c(1,3)]
# there is a parameter called mtry which is used to tune a random forest model
# we use tuneRF() function to train different models with different mtry and see which mtry gives lowest OOB (Out-Of-Bag) Error
set.seed(123)
tune.rf <- tuneRF(x = train1_full[-c(1)], y = train1_full$revenue, ntreeTry = 350)
best_mtry <- tune.rf[,"mtry"][which.min(tune.rf[,"OOBError"])] # retrieve the mtry with lowest OOB error
#best_mtry # show the best mtry value
set.seed(123) # set.seed to make sure the selection of tree samples are the same if we re-run the code
rev_rf.tune = randomForest(revenue~. , train1_full, mtry = 4, ntree = 350)
rev_rf.tune
# predicting the model on the testing data
rev_rf.test1 <- predict(rev_rf.tune, test1_full)
actual_pred_rf.test1 <- as.data.frame(cbind(actuals = test1_full$revenue, predicteds = rev_rf.test1))
metrics_test_rf1  <- regr.eval(actual_pred_rf.test1$actuals, actual_pred_rf.test1$predicteds)
options(scientific=T, digits = 2) # change format for easier comparison with metrics from previous model
metrics_test_rf1[c(1,3)]
#rev_rf.tune$predicted
rev_rf.train1 <- predict(rev_rf.tune) # same results as rev_rf.tune$predicted, both codes return the predicted values in the training set
actual_pred_rf.train1 <- as.data.frame(cbind(actuals = train1_full$revenue, predicteds = rev_rf.train1))
metrics_train_rf1 <- regr.eval(actual_pred_rf.train1$actuals, actual_pred_rf.train1$predicteds)
metrics_train_rf1[c(1,3)]
options(scientific=T, digits = 3) # change back to our initial format
PCAxform <- function(df, z=TRUE) {
#' Obtain the dataframe with the Principal Components after the rotation.
#' ELo 201903 GWU DATS
#' @param df The dataframe.
#' @param z T/F or 0/1 for z-score to be used
#' @return The transformed dataframe.
#' @examples
#' tmp = PCAxform(USArrests,TRUE)
z = ifelse(z==TRUE || z=="true" || z=="True" || z=="T" || z=="t" || z==1 || z=="1", TRUE, FALSE) # standardize z
if(z) { df = data.frame(scale(df))}  # scale not safe for non-numeric colunms, but PCA requires all variables numerics to begin with.
nmax = length(df)
pr.out = prcomp(df,scale=z)
df1 = data.frame()
cnames = c()
for( i in 1:nmax ) {
vec = 0
cnames = c( cnames, paste("PC",i, sep="") )
for( j in 1:nmax ) { vec = vec + pr.out$rotation[j,i]*df[,j] }
if( length(df1)>0 ) { df1 = data.frame(df1,vec) } else { df1 = data.frame(vec) }
}
colnames(df1) <- cnames
return(df1)
}
# To-be-implemented: for z=TRUE, it will be better to have the z-scaling option for x-vars and y separately. It is actually convenient keep y in original units.
PCRxform <- function(df, y, zX=TRUE, zy=FALSE) {
#' Obtain the dataframe with the Principal Components after the rotation for PCRegression. Requires related function PCAxform()
#' ELo 201903 GWU DATS
#' @param df The dataframe.
#' @param y The y-variable column index number(int), or the name of y-variable
#' @param zX T/F or 0/1 for z-score used on X-variables
#' @param zy T/F or 0/1 for z-score used on the target y-variable
#' @return The transformed dataframe.
#' @examples
# take care of y target
zy = ifelse(zy==TRUE || zy=="true" || zy=="True" || zy=="T" || zy=="t" || zy==1 || zy=="1", TRUE, FALSE) # standardize target y
if( is.integer(y) ) { # y is integer
if( y>length(df) || y<1 ) {
print("Invalid column number")
return(NULL)
}
if(zy) { df1 = data.frame( scale(df[y]) ) } else { df1 = df[y] } # save y-var in df1
df = df[-y] # remove y-variable in df
} else { # y is not integer, so interpret as name
if(zy) { df1 = data.frame( scale( df[names(df) == y] ) ) } else { df1 = df[names(df) == y] }
df = df[names(df) != y] # remove y-variable in df
}
if( length(df1)<1 ) {
print("Variable name not found in data.frame")
return(NULL)
}
# now transform X-vars
zX = ifelse(zX==TRUE || zX=="true" || zX=="True" || zX=="T" || zX=="t" || zX==1 || zX=="1", TRUE, FALSE) # standardize X-vars
df2 = PCAxform(df,zX)
df1 = data.frame(df1,df2) # piece them back together
return(df1)
}
loadPkg("pls")
loadPkg("mice")
#loadPkg("ISLR")
pr = prcomp(movie_num[c(1:6)] , scale =FALSE)
pr_scale = prcomp(movie_num[c(1:6)], scale =TRUE)
summary(pr)
#pr$rotation
summary(pr_scale)
#pr_scale$rotation
pr.var <- (pr$sdev^2)
pve <- pr.var/sum(pr.var)
plot(cumsum(pve), xlab="Principal Component (standardized)", ylab ="Cumulative Proportion of Variance Explained",ylim=c(0,1),type="b", main ="Non-centered version")
pr_scale.var <- (pr_scale$sdev^2)
pve_scale  <- pr_scale.var/sum(pr_scale.var)
plot(cumsum(pve_scale), xlab="Principal Component (non-standardized)", ylab ="Cumulative Proportion of Variance Explained",ylim=c(0,1),type="b", main ="Centered version")
# we used the train and test sets in linear regression model
# at first we use the PCRxform function (Prof. EL) to scale and rotate
# training set
# we do not scale the response revenue but scale all predictors
movie_pcr = PCRxform(train1[c(1:6)],"revenue",TRUE,FALSE)  # scaled predictors
#movie_pcr
# testing set
movie_pcr_test = PCRxform(test1[c(1:6)],"revenue",TRUE,FALSE)
#movie_pcr_test
# non-centered version, nothing is scaled
movie_pcr.nc = PCRxform(train1[c(1:6)],"revenue",FALSE, FALSE)  # non-scaled predictors
#movie_pcr.nc
movie_pcr.nc_test = PCRxform(test1[c(1:6)],"revenue",FALSE, FALSE)
#movie_pcr.nc_test
# scaled data
pcr.fit <- pcr(revenue~.,data=movie_pcr,scale=FALSE,validation="CV") # build the model, as we scaled data before we use scale = F here
# non-scaled data
pcr.fit.nc <- pcr(revenue~.,data=movie_pcr.nc,scale=FALSE,validation="CV")
validationplot(pcr.fit.nc,val.type="MSEP", legend="topright")
validationplot(pcr.fit.nc,val.type="R2")
validationplot(pcr.fit,val.type="MSEP", legend="topright") # validation with MSEP & R2
validationplot(pcr.fit,val.type="R2")
coefplot(pcr.fit, intercept=TRUE) # plot coefficients of different components
# position 1 is the intercept, the first PC starts at position 2
# we can see the summary of the model
summary(pcr.fit.nc)
summary(pcr.fit)
variance.pcr = c(1:5) # create a vector to store the variances for different numbers of components
for (i in 1:5) {
pcr_pred <- predict(pcr.fit, movie_pcr_test , ncomp = i); # predicting the PCR model on the testing set
# calculate the variance by returning the mean of  [predicted value - mean(actual values)] ^2
variance.pcr[i] = mean((pcr_pred - mean(movie_pcr_test$revenue))^2)
# calculate the variance by taking mean of( (predicted value - mean(actual values) ^2 )
}
var.pcr.df = as.data.frame(cbind(variance=variance.pcr, components = c(1:5)))
#pred_act <- data.frame(cbind(pcr_pred, movie_pcr_test$revenue))
ggplot(data=var.pcr.df) +
geom_line(aes(x = components, y = variance)) +
geom_point(aes(x = components, y = variance)) +
theme_light()
pcr_lm5 <- lm(revenue ~ PC1 + PC2 , data = movie_pcr.nc) # linear model with PC1 and PC2
summary(pcr_lm5)
vif(pcr_lm5)
pcr_lm4 <- lm(revenue ~ PC1 + PC2 , data = movie_pcr)
summary(pcr_lm4)
vif(pcr_lm4)
AIC(object = pcr_lm4)
BIC(object = pcr_lm4)
AIC(object = pcr_lm5)
BIC(object = pcr_lm5)
#str(movie)
if (require("pls")) {detach("package:pls", unload = T)  # for some reason package "pls" made the corrplot not proper so I detach it after using
}
# Prior check the dependence of genres and profitable
contable1 <- table(movie$genres, movie$profitable)
chisqres1 = chisq.test(contable1)
chisqres1
# Prior check the dependence of company and profitable
contable2 <- table(movie$company, movie$profitable)
chisqres2 = chisq.test(contable2)
chisqres2
# Prior check the dependence of season and profitable
contable3 <- table(movie$season, movie$profitable)
chisqres3 = chisq.test(contable3)
chisqres3
# we do some preparation with the data for our logit model
movie_nd <- movie_num # duplicate the dataframe of numerical variables
# append back the other columns
movie_nd$genres = movie$genres
movie_nd$company = movie$company
movie_nd$season = movie$season
movie_nd$y = movie$profitable # profitable column (negative profit = 0, positive profit = 1) is saved as y
str(movie_nd)
# split the train and test sets with ratio 50:50
#set.seed(1)
#movie_sample1 <- sample(2, nrow(movie_scale), replace=TRUE, prob=c(0.50, 0.50))
# create train and test sets
#train2 <- movie_scale[movie_sample1==1, 1:9]
#test2 <- movie_scale[movie_sample1==2, 1:9]
loadPkg("bestglm")
res.bestglm0 <- bestglm(Xy = movie_nd, family = binomial,
IC = "AIC",                 # Information criteria for
method = "exhaustive")
#summary(res.bestglm)
res.bestglm0$BestModels
# we will use the same train and test sets as in previous chapters
# remove revenue column and use other predictors in train and test sets
train3 <- movie_nd[movie_sample == 1, 2:10] # revenue column is 1, we do not include it
test3 <- movie_nd[movie_sample == 2, 2:10]
dim(train3)
dim(test3)
prf_glm <- glm(y ~ ., data = train3, family = "binomial")
summary(prf_glm)
exp(coef(prf_glm))[24:28] # company
exp(coef(prf_glm))[7:23] # genres
exp(coef(prf_glm))[29:31] # seasons
#length(coef(prf_glm))
loadPkg("aod")  # Analysis of Overdispersed Data, used wald.test in logit example
wald.test(b = coef(prf_glm), Sigma = vcov(prf_glm), Terms = 7:23)
wald.test(b = coef(prf_glm), Sigma = vcov(prf_glm), Terms = 24:28)
wald.test(b = coef(prf_glm), Sigma = vcov(prf_glm), Terms = 29:31)
#drop revenue
res.bestglm <- bestglm(Xy = train3, family = binomial,
IC = "AIC",                 # Information criteria for
method = "exhaustive")
#summary(res.bestglm)
res.bestglm$BestModels
#summary(res.bestglm$BestModels)
prf_glm0 <- glm(y ~  budget + score + vote + company + season, data = train3, family = "binomial")
summary(prf_glm0)
#AIC(prf_glm0) # we can check AIC and BIC
#BIC(prf_glm0)
exp(coef(prf_glm0))
prof_glm_pred = predict(object = prf_glm0, test3, type = c("response")) # predict the model on testing data and return predicted probabilities
loadPkg("ResourceSelection") # function hoslem.test( ) for logit model evaluation
# best model
prf_Hos0 = hoslem.test(test3$y, prof_glm_pred) # Hosmer and Lemeshow test, a chi-squared test
prf_Hos0
loadPkg("pROC")
h0 <- roc(test3$y ~ prof_glm_pred) # using the model on testing data and see the ROC curve and AUC
auc(h0) # area-under-curve prefer 0.8 or higher.
plot(h0)
title("Best Model ROC")
loadPkg("pscl") # use pR2( ) function to calculate McFadden statistics for model eval
prf_mcFadden = pR2(prf_glm0)
prf_mcFadden
#confusion matrix
loadPkg("caret")
logit_accuracy <- c(1:5)
threshold_logit <- c(0.5, 0.6, 0.7, 0.8, 0.9) # set threshold for predicted probabilities
j = 1
for (i in c(0.5, 0.6, 0.7, 0.8, 0.9)) {
conf_matrix <- confusionMatrix(data = as.factor(as.integer(prof_glm_pred>i)), reference = test3$y); # using the model on the testing data
logit_accuracy[j] <- conf_matrix$overall[1]*100;
j = j+1
}
# we can see the results at threshold = 0.9 as an example
confusionMatrix(data = as.factor(as.integer(prof_glm_pred>0.9)), reference = test3$y)
# combine results into a dataframe
logit_prediction <- as.data.frame(cbind(threshold = threshold_logit, accuracy = logit_accuracy))
logit_prediction
loadPkg("ISLR")
loadPkg("tree")
loadPkg("rpart")
loadPkg("rpart.plot")
loadPkg("rattle") # For fancyRpartPlot (Trees) Answer "no" on installing from binary source
# we use the same training and testing data so that we can compare Classification Tree to Logit Regression
prf_dt <- rpart(y~., method = "class", data=train3) #rpart to build our tree
summary(prf_dt) # detailed summary of splits
prf_dt$variable.importance#variable importance
#printcp(prf_dt) # display the results
# plot tree
prp(prf_dt, main = "Classification Trees for Profit Status")
#rpart.plot(prf_dt,main = "Classification Trees for Profit Status")
fancyRpartPlot(prf_dt, main = "Classification Trees for Profit Status")
printcp(prf_dt) # display the results
plotcp(prf_dt) # visualize cross-validation results
prf_dt_prune <- prune(prf_dt, cp = prf_dt$cptable[which.min(prf_dt$cptable[,"xerror"]),"CP"]) # prune trees at cp where xerror is minimum
# plot tree
prp(prf_dt_prune, main = "Classification Trees for Profit Status")
#rpart.plot(prf_dt_prune,main = "Classification Trees for Profit Status")
fancyRpartPlot(prf_dt_prune, main = "Classification Trees for Profit Status")
prf_dt.pred <- predict(prf_dt_prune, test3, type = "class" ) # predict the model on the testing data
table_dt <- table(actual = test3$y, predicted = prf_dt.pred) # create a confusion matrix of predicted and actual values
table_dt
# Accuracy Calculation
sum(diag(table_dt))/sum(table_dt) # sum(true positive + false negative)/ total
#length(prf_dt.pred)
# I see the method to plot ROC for classification tree in youtube and stackoverflow
# There is an option: type = "prob" when predict rpart object, it return predicted probabilities by the classification tree
# I then realize that the values with predicted probabilites > 0.5 are the values predicted as 1 in the above method (chunk Q92)
# I create the another confusion matrix for this part and set threshold = 0.5 and see that the confusion matrices are also similar
# prediction using type = "prob"
prf_dt.pred1 <- predict(prf_dt_prune, test3, type = "prob" )
prf_dt.conf <- confusionMatrix(data = as.factor(as.integer(prf_dt.pred1[,2]>0.5)), reference = test3$y)
# the accuracy will be the same as the accuracy we calculate when setting type=class, we can see the results to check it
prf_dt.conf # the accuracy is also 80.5% and the confusion matrix is the same too
#plot ROC and see AUC
h_dt <- roc(test3$y ~ prf_dt.pred1[,2])
auc(h_dt)
plot(h_dt)
loadPkg("class")
# we use the same train and test sets as in the linear model section
#train2 <- as.data.frame(scale(movie_num, center = TRUE, scale = TRUE))
#train2$genres <- movie[movie_sample==1, 1:14]$genres
#train set
train2 <- train1_full  # dupicate the train set with all predictors we created above
train2$revenue <- scale(train2$revenue, center = TRUE, scale = TRUE) # scale the revenue column, other numerical variables were scaled before
# numerical colums range from 1:6; 7:9 are our reponses
# same with test set
test2 <- test1_full
test2$revenue <- scale(test2$revenue, center = TRUE, scale = TRUE)
#str(train2)
#str(test2)
set.seed(123) # set seed to make sure the table won't change after we re-run the code
season_knn <- knn(train = train2[,c(1:6)], test = test2[,c(1:6)], cl=train2$season, k=9)
loadPkg("gmodels")
crosstab <- CrossTable(test2$season, season_knn, prop.chisq = FALSE)
chooseK = function(k, train_set, val_set, train_class, val_class){
# Build knn with k neighbors considered.
class_knn = knn(train = train_set,    #<- training set cases
test = val_set,       #<- test set cases
cl = train_class,     #<- category for classification
k = k,                #<- number of neighbors considered
use.all = TRUE)       #<- control ties between class assignments
#   If true, all distances equal to the kth
#   largest are included
tab = table(class_knn, val_class)
# Calculate the accuracy.
accu = sum(tab[row(tab) == col(tab)]) / sum(tab)
cbind(k = k, accuracy = accu)
}
set.seed(123)
knn_season_k = sapply(seq(1, 41, by = 2),  #<- set k to be odd number from 1 to 21
function(x) chooseK(x,
train_set = train2[c(1:6)],
val_set = test2[c(1:6)],
train_class = train2$season,
val_class = test2$season))
knn_season_k = data.frame(k = knn_season_k[1,],
accuracy = knn_season_k[2,])
# Plot accuracy vs. k.
ggplot(knn_season_k,
aes(x = k, y = accuracy)) +
geom_line(color = "orange", size = 1.5) +
geom_point(size = 3)
set.seed(123)
knn_genres_k = sapply(seq(1, 41, by = 2),  #<- set k to be odd number from 1 to 21
function(x) chooseK(x,
train_set = train2[c(1:6)],
val_set = test2[c(1:6)],
train_class = train2$genres,
val_class = test2$genres))
knn_genres_k = data.frame(k = knn_genres_k[1,],
accuracy = knn_genres_k[2,])
# Plot accuracy vs. k.
ggplot(knn_genres_k,
aes(x = k, y = accuracy)) +
geom_line(color = "orange", size = 1.5) +
geom_point(size = 3)
set.seed(123)
company_knn <- knn(train = train2[,c(1:6)], test = test2[,c(1:6)], cl=train2$company, k=9)
crosstab <- CrossTable(test2$company, company_knn, prop.chisq = FALSE)
set.seed(123)
knn_company_k = sapply(seq(1, 41, by = 2),  #<- set k to be odd number from 1 to 21
function(x) chooseK(x,
train_set = train2[c(1:6)],
val_set = test2[c(1:6)],
train_class = train2$company,
val_class = test2$company))
knn_company_k = data.frame(k = knn_company_k[1,],
accuracy = knn_company_k[2,])
# Plot accuracy vs. k.
ggplot(knn_company_k,
aes(x = k, y = accuracy)) +
geom_line(color = "orange", size = 1.5) +
geom_point(size = 3)
# we will subset our data to get the movies from 1995-2016 since we have consistent data in that range
# we use time series with frequency = 4 (by quarter)
movie_ts <- subset(movie, (year > 1994)) # subset data after 1994
movie_ts <- subset(movie_ts, select = c("revenue", "year", "quarter")) # select 3 columns we use for time series
movie_ts <- movie_ts[order(movie_ts$year),] # order by year
#unique(movie_ts$year)
#str(movie_ts)
loadPkg("dplyr")
movie_ts = movie_ts %>% group_by(year, quarter) %>% summarise_each(funs(sum)) # calculate the total revenue for each quarter in each year
movie_ts$quarter <- factor(movie_ts$quarter, levels = c("Q1", "Q2", "Q3", "Q4")) # reorder the factor levels
movie_ts <- movie_ts[order(movie_ts$year, movie_ts$quarter),] # order by year then by quarter
#movie_ts
# divide the data into 2 sets: training and testing
movie.ts <- ts(movie_ts$revenue, frequency = 4, start = c(1995,1), end = c(2010,4)) # training data from 1995-2010
movie.ts.test <- ts(tail(movie_ts, 23)$revenue, frequency = 4, start = c(2011,1), end = c(2016,3)) # testing data from 2011-2016, used for evaluating our time series model
#movie.ts.test
plot(movie.ts, xlab = "Year", ylab="Revenue")
movie_dcp <- decompose(movie.ts)
summary(movie_dcp$seasonal)
summary(movie_dcp$random)
plot(movie_dcp)
movie.ts.smth <- HoltWinters(movie.ts)
movie.ts.smth
movie.ts.smth$SSE
plot(movie.ts.smth)
loadPkg("forecast")
#accuracy(movie_hw)
movie_ft <- forecast(movie.ts.smth, h=23)
plot(movie_ft)
#sm <- ma(movie.ts, order=4) # 4 quarters moving average
#lines(sm, col="red") # plot
AIC(movie_ft)
loadPkg("forecast")
#accuracy(movie_hw)
movie_ft <- forecast(movie.ts.smth, h=23)
plot(movie_ft)
#sm <- ma(movie.ts, order=4) # 4 quarters moving average
#lines(sm, col="red") # plot
AIC(movie_ft)
loadPkg("forecast")
#accuracy(movie_hw)
movie_ft <- forecast(movie.ts.smth, h=23)
plot(movie_ft)
#sm <- ma(movie.ts, order=4) # 4 quarters moving average
#lines(sm, col="red") # plot
accuracy(movie_ft)
accuracy(movie_ft)
accuracy(movie_arima)
hchart(movie_arima) %>%
hc_add_series_ts(movie.ts.test, color = "red", name = "ACTUAL")  # general graph
# more detailed graph, Itry different stuffs here too
highchart(type="chart") %>%        # try type = "chart", "stock" for different visualizations
hc_chart(type = "column") %>%      # try type = "line", bar", "column" for different visualizations
hc_add_series_ts(movie.ts.test,name = "ACTUAL", color = "red" ) %>%   # plot the actual data labeled by red color
hc_add_series(name = "PREDICTED", movie_arima, color = "blue" )  %>%     # plot the hw predictions labeled by blue color
hc_legend(align = "left", verticalAlign = "top",
layout = "vertical", x = 0, y = 100)
accuracy(movie_ft, movie.ts.test )
accuracy(movie_arima, movie.ts.test)
accuracy(movie_ft, movie.ts)
accuracy(movie_ft, movie.ts.test)
accuracy(movie_arima, movie.ts.test)
plot(movie.ts.smth)
movie.ts.smth <- HoltWinters(movie.ts, seasonal = FALSE)
movie.ts.smth <- HoltWinters(movie.ts)
movie.ts.smth
movie.ts.smth$SSE
ggplot(movie_ts, aes(x=quarter, y=revenue)) +
geom_boxplot()
ggplot(movie_ts, aes(x=quarter, y=revenue), fill = quarter) +
geom_boxplot()
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
geom_boxplot()
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
geom_boxplot(fill = c("red","blue","yellow","green"), alpha = 0.8)
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
geom_boxplot(fill = c("red","dodgerblue","yellow","green"), alpha = 0.8)
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
geom_boxplot(fill = c("red","dodgerblue","yellow","darkgreen"), alpha = 0.8)
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
geom_boxplot(fill = c("red","dodgerblue","yellow","turquoise"), alpha = 0.8)
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
geom_boxplot(fill = c("red","dodgerblue","yellow","turquoise"), alpha = 0.9)
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
geom_boxplot(alpha = 0.9) +
guides(fill=guide_legend(title = "Season"))
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
geom_boxplot(alpha = 0.9) +
guides(fill=guide_legend(title = "Quarter"))
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
geom_boxplot(alpha = 0.8) +
guides(fill=guide_legend(title = "Quarter"))
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
geom_boxplot(fill = c("red","dodgerblue","chocolate","green"),alpha = 0.8) +
guides(fill=guide_legend(title = "Quarter"))
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
geom_boxplot(fill = c("red","dodgerblue","yellow","green"),alpha = 0.8) +
guides(fill=guide_legend(title = "Quarter"))
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
ggtitle("Revenue distribution by quarter")
geom_boxplot(fill = c("red","dodgerblue","yellow","green"),alpha = 0.8) +
them_bw() +
theme(plot.title = element_text(hjust = 0.5))
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
ggtitle("Revenue distribution by quarter")
geom_boxplot(fill = c("red","dodgerblue","yellow","green"),alpha = 0.8) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
ggtitle(main="Revenue distribution by quarter") +
geom_boxplot(fill = c("red","dodgerblue","yellow","green"),alpha = 0.8) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
ggplot(movie_ts, aes(x=quarter, y=revenue, fill = quarter)) +
ggtitle("Revenue distribution by quarter") +
geom_boxplot(fill = c("red","dodgerblue","yellow","green"),alpha = 0.8) +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
accuracy(movie_ft, movie.ts.test)
accuracy(movie_arima, movie.ts.test)
loadPkg("corrplot")
movie_num <- subset(movie, select = c(6,1,3,7,9,10)) # choose numerical variables excluding profit to be the data for later model
movie_num_all <- data.frame(cbind(movie_num,profit=movie$profit)) # this one includes profit
#cordf_all = cor(movie_num_all)
#corrplot(cordf_all)
cordf =  cor(movie_num) # cor matrix
corrplot(cordf) # correlation plot
